<!DOCTYPE html>
<html>

<head>
  <title>Rahul Krishna</title>
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
<style type="text/css">
<!--
 .tab { margin-left: 40px; }
-->
</style>
</head>

<body>
  <nav class="sidebar">
  
    <div class="header">
      <h1>Rahul Krishna</h1>
      <p>Mathematician</p>
      <div id="mugshot"><img src="photo.png"></div>
    </div>

    <ul>
      <a href="#bio" class="navlink">
        <li class="selected">Bio</li>
      </a>
      <a href="#cv" class="navlink">
        <li>CV & Resume</li>
      </a>
      <a href="#research" class="navlink">
        <li>Research</li>
      </a>
      <a href="#teaching" class="navlink">
        <li>Teaching</li>
      </a>
      <a href="#projects" class="navlink">
        <li>Projects</li>
      </a>
    </ul>
  </nav>


  <div class="main">

    <section id="bio" class="active">
      <h2>Bio</h2>
      
      <p>
        I am a mathematician looking for jobs in industry and government. Previously, I was a postdoctoral instructor at Brandeis University and a Boas Assistant Professor at Northwestern University, working in number theory and representation theory.  I am currently interested in more applied disciplines within mathematics and statistics, including cryptography, machine learning, and data science.

        <br><br>

        Ph.D. in Mathematics, Columbia University, 2016.
        <br>
        BA in Mathematics, Princeton University, 2010.

      </p>
    </section>


    <section id="cv">
      <h2>Curriculum Vitae</h2> 
      <p><embed src="cv.pdf" width="500" height="375" 
 type="application/pdf"></p>
      <p>Last updated: October 2023</p>
      <h2>Resume</h2> 
      <p><embed src="resume.pdf" width="500" height="375" 
 type="application/pdf"></p>
      <p>Last updated: Aug 2024</p>
    </section>


    <section id="research">
      <h2>Research</h2>
      <ul>
        <li><u>On the global Gross-Prasad conjecture for orthogonal groups</u> (In preparation.)
        <br>
        Building on "A new proof of the Waldspurger formula I," I construct an RTF comparison strategy aimed at the global Gross-Prasad conjecture for orthogonal groups. This essentially reduces the global Gross-Prasad conjecture to local conjectures of "smooth transfer" and "fundamental lemma" type. I verify the fundamental lemma by hand in some low rank examples.</li>
        <li> <a href="research/waldspurgerI.pdf">A new proof of the Waldspurger formula I</a> (<a href="https://msp.org/ant/2019/13-3/p02.xhtml">Algebra and Number Theory, 2019.</a>)
        <br>
        I construct a new comparison between two very different relative trace formulas (RTFs). These RTFs are designed so that their spectral sides "encode" Waldspurger's formula for toric periods; they are also designed keeping the interpretation of Waldspurger's formula as the low rank version of the global Gross-Prasad in mind. I set up an orbit-by-orbit matching, and conjecture and prove statements of "smooth transfer" and "fundamental lemma" type in this setting. This approach should, with further work on regularization of these RTFs, lead to a completely new and independent proof of Waldspurger's formula.</li>
      </ul>
      <br>
      Here are a few papers that have gotten put on the back burner. I hope to return to them soon.
      <br>
      <ul>
        <li><u>Beyond endoscopy for spherical varieties of rank one: the fundamental lemma</u>, joint with D. Johnstone.  (In preparation.)
        <br>
        We verify the fundamental lemma of Y. Sakellaridis in his "relative beyond endoscopy" program for spherical varieties of rank one.</li>

        <li><u>A new proof of the Waldspurger formula II</u> (In preparation.)
        <br>
        I explain how to regularize the relative trace formulas in "A new proof of the Waldspurger formula I," and deduce a global character identity equivalent to Waldspurger's formula.

        </li>
      </ul>
      <h2>Expository</h2>
      <h3> Machine Learning</h3>
      <ul>
        <li><a href="notes/ML/Mercer_s_theorem_and_RKHS.pdf">Mercer theory: a survey</a>
        <br>
        I explain the proof of Mercer's theorem, in both its measurable and continuous forms. I also take the opportunity to summarize some basic results in the spectral theory of (bounded) symmetric operators on a Hilbert space.</li>
      </ul>
      <h3> Quantum Computing</h3>
      <ul>
      <li><u>Quantum error correction</u> (In preparation.)
        <br>
        I go over of the basic theory of (classical and quantum) error correcting codes. </li>
      </ul> 
      
    </section>


    <section id="teaching">
      <h2>Teaching</h2>
      <p><b>At Brandeis:</b></p>
      <ul>
        <li>Spring 2023; Math 115A, Introduction to complex analysis </li>
        <li>Spring 2023; Math 20A, Mulivariable calculus (Calc III)</li>
        <li>Autumn 2022; Math 252A, Graduate algbraic geometry </li>
        <li>Autumn 2022; Math 211A, Graduate real analysis </li>
        <li>Spring 2022; Math 115A, Introduction to complex analysis </li>
        <li>Autumn 2021; Math 100A, Introduction to abstract algebra </li>
        <li>Autumn 2021; Math 35A, Advanced calculus and fourier analysis </li>
        <li>Spring 2021; Math 15A, Applied linear algebra </li>
        <li>Autumn 2020; Math 211A, Graduate real analysis </li>
        <li>Autumn 2020; Math 23B, Introduction to proofs </li>
        <li>Spring 2020; Math 15A, Applied linear algebra </li>
        <li>Spring 2020; Math 23B, Introduction to proofs </li>
        <li>Autumn 2019; Math 15A, Applied linear algebra </li>
      </ul>

      <p><b> At Northwestern: </b></p>
      <ul>
       <li>Spring 2019; Math 230, Differential multivariable calculus (Calc III) </li>
       <li>Fall 2018; Math 230, Differential multivariable calculus (Calc III) </li>
       <li>Spring 2018; Math 482-2, An introduction to the trace formula. A very incomplete set of lecture notes are available <a href="notes/Teaching/S2018-482-2/Notes_on_the_trace_formula.pdf">here</a>, and a partial collection of homework problems is available <a href="notes/Teaching/S2018-482-2/TF_Exercises.pdf">here</a>. By clicking on the links above, you agree to inform me of any errors (mathematical or otherwise) you find. A quick remark: the notes cover much of the classical theory of the trace formula for finitely generated Fuchsian groups acting on the upper half plane. I also discussed the adelic perspective for $\mathrm{GL}_2$ in class; however, these notes have yet to be edited and typed up. Be warned! </li>
       <li>Spring 2018; Math 224, Integral single variable calculus (Calc II) </li>
       <li>Fall 2017; Math 224, Integral single variable calculus (Calc II) </li>
       <li>Spring 2017; Math 482-2, Elliptic curves and modular forms. </li>
       <li>Spring 2017; Math 230, Differential multivariable calculus (Calc III) </li>
       <li>Fall 2016: Math 224, Integral single variable calculus (Calc II) </li>
      </ul>

      <p> <b> At Columbia: </b></p>
      <ul>
        <li>Autumn 2016; Math 1103, Integral calculus (Calc II) </li>
        <li>Autumn 2015; Math 1003, College algebra and analytic geometry (Precalc) </li>
        <li>Summer 2014; Math 1201, Differential multivariable calculus (Calc III) </li>
        <li>Summer 2011; Math 1103, Integral single variable calculus (Calc II) </li>
      </ul>
    </section>


    <section id="projects">
      <h2>Projects</h2> 
      <p>Here are some side projects I have worked on in the past.</p>

      <h3><a href="https://github.com/rmkrishn/pred-pol-trading-lobbying">Money in politics and politicians in money</a>  </h3>
      <p class="tab"> (joint with Paul VanKoughnett) </p>
      <p><a href="https://www.erdosinstitute.org/project-database/spring-2024/data-science-boot-camp/money-in-politics-and-politicians-in-money"> Presentation and summary. </a> </p>
      <p> This is a data science project, carried out as part of the Erdos Institute Spring 2024 semester. <br>
      In this project, we worked with two sources of data: 
      <ol>
        <li>Lobbying disclosures, available from the Office of the Senate. </li> 
        <li>Individual financial disclosures of congresspeople, obtained through QuiverQuant.</li>
      </ol>
      From the lobbying disclosures (1), we extract data on how much spending occurs per quarter by companies, and what broad topics/issues they are lobbying about. From (2), we extract data on what individual stocks congresspeople are trading at a given time.
      The goal of the project is to try to identify the extent to which lobbying data (1) can help to predict trading behavior of politicians, as measured by (2). <br>
      We found, after trying a number of different time series models, that while there is no visible correlation between lobbying activity and trading, a multivariate VARIMA model that takes lobbying into account significantly outperforms a univariate model. </p>
    
   <h3><a href="https://github.com/julianrosen/erdos_dl_recanvo_project">A Vocal-Cue Interpreter for Minimally Verbal Individuals</a>   </h3>
      <p class="tab"> (joint with Monalisa Dutta, Sarasi Jayasekara, Alessandro Malus√†, Atharva Patil, and Julian Rosen)</p>
      <p><a href= "https://www.erdosinstitute.org/project-database/may-summer-2024/deep-learning-boot-camp/a-vocal-cue-interpreter-for-minimally-verbal-individuals"> Presentation and summary. </a> </p>
      <p> This is a deep learning project, carried out as part of the Erdos Institute Summer 2024 semester. We won a "top project" award for this work.<br>
        Nonverbal vocalizations play an important role in communication, particularly for individuals with few spoken words. While caretakers of minimally-verbal individuals often learn to interpret nonverbal vocalizations, the vocalizations can be difficult to interpret by people unfamiliar with the individual. <br>
        In this project, we used the ReCANVo dataset - a dataset of nonverbal vocalizations by minimally verbal individuals, labelled with meanings by their caretakers - to train a model that can accurately predict labels. <br>
        After much experimentation, we obtained good results by combining a pretrained transformer model (pretrained HuBERT) for feature extraction together with a 3-layer feed forward neural net for classification.
    </section>
  </div>
  <script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js"></script>
  <script type="text/javascript" src="script.js"></script>
</body>

</html>
